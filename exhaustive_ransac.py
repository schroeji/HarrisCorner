## A version of "exhaustive RANSAC" designed to find the best offset relating
## two images, given a set of possibly noisy matches.  Although not
## *random* consensus, it keeps the spirit of RANSAC by finding the offset
## for which there is the strongest consensus in the input data.
##

import numpy as np


def basic_RANSAC(matches, coord_list1, coord_list2, match_dist=1.6):
    """Carry out a simple version of the RANSAC procedure for calculating
       the appropriate translation needed to map image 2 onto image 1.
       N.B., this isn't true RANSAC because it doesn't carry out *random*
       consensus, instead it works exhaustively: for each offset in the
       list of possible offsets it checks to see how many other offsets
       agree with it (that point's consensus set), then returns the average
       offset of all the points in the largest consensus set.  Hence it is
       not performing *random* consensus, but rather *exhaustive*
       consensus.

       matches - List of matches, i.e., index pairs, (i1,i2). i1 is the
       index of the matching coordinate from coord_list1 and i2 the index
       of the coordinate in coord_list2 that it matches.  This list of
       matches is generated by a previous call to "match".

       coord_list1, coord_list2 -- lists of interest point coordinates in
       the first and second images.

       match_dist -- maximum distance between offsets for them to be
       considered part of a consensus set.

       Returns -- (row_offset,column_offset,match_count) -- a tuple,
       the first two elements are the best_offset relating the second image to
       the first, the third is the number of point-pairs supporting this
       offset according to this "Exhaustive RANSAC" matcher, i.e., the
       "strength" of this offset.
    """
    d2 = match_dist**2  ##  Square the match distance.
    ## Build a list of offsets from the lists of matching points for the
    ## first and second images.
    offsets = np.zeros((len(matches), 2))
    for i in range(len(matches)):
        index1, index2 = matches[i]
        offsets[i, 0] = coord_list1[index1][0] - coord_list2[index2][0]
        offsets[i, 1] = coord_list1[index1][1] - coord_list2[index2][1]
    ## Run the comparison.  best_match_count keeps track of the size of the
    ## largest consensus set, and (best_row_offset,best_col_offset) the
    ## current offset associated with the largest consensus set found so far.
    best_match_count = -1
    best_row_offset, best_col_offset = 1e6, 1e6
    for i in range(len(offsets)):
        match_count = 1.0
        offi0 = offsets[i, 0]
        offi1 = offsets[i, 1]
        ## Only continue into j loop looking for consensus if this point hasn't
        ## been found and folded into a consensus set earlier.  Just improves
        ## efficiency.
        if (offi0 - best_row_offset)**2 + (offi1 - best_col_offset)**2 >= d2:
            sum_row_offsets, sum_col_offsets = offi0, offi1
            for j in range(len(matches)):
                if j != i:
                    offj0 = offsets[j, 0]
                    offj1 = offsets[j, 1]
                    if (offi0 - offj0)**2 + (offi1 - offj1)**2 < d2:
                        sum_row_offsets += offj0
                        sum_col_offsets += offj1
                        match_count += 1.0
            if match_count >= best_match_count:
                best_row_offset = sum_row_offsets / match_count
                best_col_offset = sum_col_offsets / match_count
                best_match_count = match_count
    return best_row_offset, best_col_offset, best_match_count
